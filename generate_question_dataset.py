#!/usr/bin/env python3
"""
é€šè¿‡deepseek APIç”ŸæˆMerlin Chain function callingé—®é¢˜æ•°æ®é›†
"""
import asyncio
import argparse
from typing import List, Dict
from deepseek_api_client import DeepSeekAPIClient
from dataset_utils import DatasetUtils

class QuestionDatasetGenerator:
    """é—®é¢˜æ•°æ®é›†ç”Ÿæˆå™¨ï¼Œç”Ÿæˆç”¨æˆ·é—®é¢˜å’Œå¼•å¯¼å¯¹è¯"""
    
    def __init__(self, api_key: str):
        self.api_client = DeepSeekAPIClient(api_key)
        self.utils = DatasetUtils()
    
    async def generate_batch(self, system_prompt: str, batch_num: int, batch_size: int = 10) -> List[Dict]:
        """ç”Ÿæˆä¸€æ‰¹å¯¹è¯æ•°æ®"""
        print(f"æ­£åœ¨ç”Ÿæˆç¬¬ {batch_num} æ‰¹æ•°æ®...")
        
        # ç²¾ç®€çš„promptå˜ä½“ï¼Œè¦†ç›–æ‰€æœ‰Merlin MCPå·¥å…·
        prompt_variations = [
            # äº¤æ˜“æŸ¥è¯¢ç±»
            f"ç”Ÿæˆ{batch_size}ä¸ªé—®é¢˜ï¼Œé—®é¢˜å±äºä»¥ä¸‹ä¸»é¢˜ï¼šæŸ¥è¯¢äº¤æ˜“è¯¦æƒ…ã€è·å–åŒºå—äº¤æ˜“ã€æœ€æ–°äº¤æ˜“åœºæ™¯",
            # åœ°å€åˆ†æç±»  
            f"ç”Ÿæˆ{batch_size}ä¸ªé—®é¢˜: é—®é¢˜å±äºä»¥ä¸‹ä¸»é¢˜ï¼šé’±åŒ…ä½™é¢ã€åœ°å€è¯¦æƒ…ã€èµ„äº§ä»·å€¼ã€æŒä»“åˆ†æåœºæ™¯",
            # ä»£å¸ä¿¡æ¯ç±»
            f"ç”Ÿæˆ{batch_size}ä¸ªé—®é¢˜: é—®é¢˜å±äºä»¥ä¸‹ä¸»é¢˜ï¼šä»£å¸ä»·æ ¼ã€å¸‚åœºæ•°æ®ã€ä»·æ ¼å˜åŒ–ã€äº¤æ˜“é‡åœºæ™¯",
            # åŒºå—æŸ¥è¯¢ç±»
            f"ç”Ÿæˆ{batch_size}ä¸ªé—®é¢˜: é—®é¢˜å±äºä»¥ä¸‹ä¸»é¢˜ï¼šåŒºå—è¯¦æƒ…ã€æœ€æ–°åŒºå—ã€åŒºå—å†…äº¤æ˜“ç­‰åœºæ™¯",
            # æŒæœ‰è€…åˆ†æç±»
            f"ç”Ÿæˆ{batch_size}ä¸ªé—®é¢˜: é—®é¢˜å±äºä»¥ä¸‹ä¸»é¢˜ï¼šä»£å¸æŒæœ‰è€…ã€è½¬è´¦è®°å½•ã€èµ„äº§åˆ†å¸ƒåœºæ™¯",
            # æœç´¢å‘ç°ç±»
            f"ç”Ÿæˆ{batch_size}ä¸ªé—®é¢˜: é—®é¢˜å±äºä»¥ä¸‹ä¸»é¢˜ï¼šé“¾ä¸Šæœç´¢ã€ä»£å¸æŸ¥æ‰¾ã€åœ°å€æœç´¢åœºæ™¯",
            # Nativeä»£å¸ç±»
            f"ç”Ÿæˆ{batch_size}ä¸ªé—®é¢˜: é—®é¢˜å±äºä»¥ä¸‹ä¸»é¢˜ï¼šBTCä»·æ ¼ã€åŸç”Ÿä»£å¸ä¿¡æ¯ã€å®æ—¶ä»·æ ¼åœºæ™¯",
            # ç»¼åˆæŸ¥è¯¢ç±»
            f"ç”Ÿæˆ{batch_size}ä¸ªé—®é¢˜: é—®é¢˜å±äºä»¥ä¸‹ä¸»é¢˜ï¼šæ··åˆæŸ¥è¯¢ï¼Œæ¶µç›–äº¤æ˜“ã€åœ°å€ã€ä»£å¸åœºæ™¯"
        ]
        
        # æ ¹æ®æ‰¹æ¬¡å·é€‰æ‹©ä¸åŒçš„promptå˜ä½“ï¼Œå¹¶æ·»åŠ é€šç”¨æŒ‡å¯¼åŸåˆ™
        base_prompt = prompt_variations[batch_num % len(prompt_variations)]
        user_prompt = f"{base_prompt}ï¼Œå¹¶æ³¨æ„ä»¥ä¸‹å‡ ç‚¹ï¼š\n1.å¼•å¯¼ç”¨æˆ·çš„å‚æ•°ä¾‹å­ä½¿ç”¨éšæœºç”Ÿæˆçš„å€¼ã€‚\n2.ç”¨æˆ·è¯¢é—®ä»£å¸ç›¸å…³é—®é¢˜æ—¶ä¸éœ€è¦å‘ç”¨æˆ·ç´¢å–ä»£å¸åˆçº¦åœ°å€ã€‚"
        
        print(f"  ä½¿ç”¨promptå˜ä½“ {batch_num % len(prompt_variations) + 1}: {user_prompt[:50]}...")
        
        response = self.api_client.call_api(system_prompt, user_prompt)
        if not response:
            print(f"ç¬¬ {batch_num} æ‰¹æ•°æ®ç”Ÿæˆå¤±è´¥")
            return []
        
        # æ‰“å°å¤§æ¨¡å‹çš„å®Œæ•´è¾“å‡º
        print(f"\n{'='*50}")
        print(f"å¤§æ¨¡å‹åŸå§‹è¾“å‡º (æ‰¹æ¬¡ {batch_num}):")
        print(f"{'='*50}")
        print(response)
        print(f"{'='*50}\n")
        
        conversations = self.utils.extract_json_from_response(response)
        if not conversations:
            print(f"ç¬¬ {batch_num} æ‰¹æ•°æ®è§£æå¤±è´¥")
            print("å“åº”å†…å®¹:", response[:500] + "..." if len(response) > 500 else response)
            return []
        
        print(f"ç¬¬ {batch_num} æ‰¹æˆåŠŸç”Ÿæˆ {len(conversations)} ä¸ªå¯¹è¯")
        return conversations
    
    async def generate_dataset(self, prompt_file: str, total_conversations: int = 6000, batch_size: int = 50, output_file: str = "function_calling_dataset.json"):
        """ç”Ÿæˆå®Œæ•´çš„é—®é¢˜æ•°æ®é›†"""
        # è¯»å–ç³»ç»Ÿæç¤ºè¯
        system_prompt = self.utils.read_file(prompt_file)
        if not system_prompt:
            print("æ— æ³•è¯»å–promptæ–‡ä»¶")
            return
        
        all_conversations = []
        total_batches = (total_conversations + batch_size - 1) // batch_size
        
        print(f"å¼€å§‹ç”Ÿæˆé—®é¢˜æ•°æ®é›†ï¼Œç›®æ ‡: {total_conversations} ä¸ªå¯¹è¯ï¼Œåˆ† {total_batches} æ‰¹ç”Ÿæˆ")
        
        for batch_num in range(1, total_batches + 1):
            try:
                batch_conversations = await self.generate_batch(system_prompt, batch_num, batch_size)
                all_conversations.extend(batch_conversations)
                
                # ä¿å­˜ä¸­é—´ç»“æœ
                self.utils.write_json_file(batch_conversations, f"temp_question_batch_{batch_num}.json")
                
                print(f"å·²ç”Ÿæˆ {len(all_conversations)} ä¸ªå¯¹è¯")
                
                # é¿å…APIé™æµï¼Œé—´éš”ä¸€æ®µæ—¶é—´
                if batch_num < total_batches:
                    await asyncio.sleep(2)
                
            except Exception as e:
                print(f"ç”Ÿæˆç¬¬ {batch_num} æ‰¹æ•°æ®æ—¶å‡ºé”™: {e}")
                continue
        
        # ä¿å­˜æœ€ç»ˆç»“æœ
        self.utils.write_json_file(all_conversations, output_file)
        
        print(f"é—®é¢˜æ•°æ®é›†ç”Ÿæˆå®Œæˆï¼")
        print(f"æ€»è®¡ç”Ÿæˆ: {len(all_conversations)} ä¸ªå¯¹è¯")
        print(f"ä¿å­˜è‡³: {output_file}")
        
        return all_conversations

def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="ç”ŸæˆMerlin Chain function callingé—®é¢˜æ•°æ®é›†")
    parser.add_argument("--total_conversations", type=int, default=6000, help="ç›®æ ‡å¯¹è¯æ•°é‡ (é»˜è®¤: 6000)")
    parser.add_argument("--batch_size", type=int, default=50, help="æ¯æ‰¹ç”Ÿæˆçš„å¯¹è¯æ•°é‡ (é»˜è®¤: 50)")
    parser.add_argument("--output_file", type=str, default="function_calling_dataset_v2.json", help="è¾“å‡ºæ–‡ä»¶å (é»˜è®¤: function_calling_dataset_v2.json)")
    parser.add_argument("--prompt_file", type=str, default="prompt.txt", help="æç¤ºè¯æ–‡ä»¶ (é»˜è®¤: prompt.txt)")
    parser.add_argument("--api_key", type=str, help="DeepSeek API Key (å¯é€‰ï¼Œæœªæä¾›åˆ™ä½¿ç”¨é»˜è®¤å€¼)")
    return parser.parse_args()

async def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    # ä½¿ç”¨ä½ çš„APIé…ç½®
    api_key = args.api_key or "0f8fb6e0-c7b3-43a1-93af-17d8bb9da64c"  # ä½ çš„API Key
    
    print("ğŸš€ å¼€å§‹ä½¿ç”¨æ·±åº¦æ±‚ç´¢APIç”Ÿæˆé—®é¢˜æ•°æ®é›†...")
    print(f"   API Keyå‰ç¼€: {api_key[:8]}...")
    print("ğŸ“ ç”Ÿæˆfunction callingé—®é¢˜å’Œå¼•å¯¼å¯¹è¯")
    print(f"   ç›®æ ‡å¯¹è¯æ•°é‡: {args.total_conversations}")
    print(f"   æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    print(f"   è¾“å‡ºæ–‡ä»¶: {args.output_file}")
    
    generator = QuestionDatasetGenerator(api_key)
    
    try:
        # ç”Ÿæˆé—®é¢˜æ•°æ®é›†
        conversations = await generator.generate_dataset(
            prompt_file=args.prompt_file,
            total_conversations=args.total_conversations,
            batch_size=args.batch_size,
            output_file=args.output_file
        )
        
        if conversations:
            print(f"âœ… é—®é¢˜æ•°æ®é›†ç”ŸæˆæˆåŠŸï¼Œå…± {len(conversations)} ä¸ªå¯¹è¯")
            print("ğŸ’¡ ä¸‹ä¸€æ­¥è¿è¡Œ generate_complete_dataset.py æ¥ç”Ÿæˆå®Œæ•´çš„function callingæ•°æ®é›†")
        else:
            print("âŒ é—®é¢˜æ•°æ®é›†ç”Ÿæˆå¤±è´¥")
            
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")

if __name__ == "__main__":
    asyncio.run(main())